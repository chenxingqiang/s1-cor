@article{bradley-terry,
 ISSN = {00063444, 14643510},
 URL = {http://www.jstor.org/stable/2334029},
 author = {Ralph Allan Bradley and Milton E. Terry},
 journal = {Biometrika},
 number = {3/4},
 pages = {324--345},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons},
 urldate = {2024-10-31},
 volume = {39},
 year = {1952}
}

@misc{xin2024deepseekproveradvancingtheoremproving,
      title={DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data}, 
      author={Huajian Xin and Daya Guo and Zhihong Shao and Zhizhou Ren and Qihao Zhu and Bo Liu and Chong Ruan and Wenda Li and Xiaodan Liang},
      year={2024},
      eprint={2405.14333},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.14333}, 
}

@misc{diao2024activepromptingchainofthoughtlarge,
      title={Active Prompting with Chain-of-Thought for Large Language Models}, 
      author={Shizhe Diao and Pengcheng Wang and Yong Lin and Rui Pan and Xiang Liu and Tong Zhang},
      year={2024},
      eprint={2302.12246},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.12246}, 
}

@misc{xu2025redstardoesscalinglongcot,
      title={RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?}, 
      author={Haotian Xu and Xing Wu and Weinong Wang and Zhongzhi Li and Da Zheng and Boyuan Chen and Yi Hu and Shijia Kang and Jiaming Ji and Yingying Zhang and Zhijiang Guo and Yaodong Yang and Muhan Zhang and Debing Zhang},
      year={2025},
      eprint={2501.11284},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.11284}, 
}

@misc{gandhi2024streamsearchsoslearning,
      title={Stream of Search (SoS): Learning to Search in Language}, 
      author={Kanishk Gandhi and Denise Lee and Gabriel Grand and Muxin Liu and Winson Cheng and Archit Sharma and Noah D. Goodman},
      year={2024},
      eprint={2404.03683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.03683}, 
}

@misc{su2024brightrealisticchallengingbenchmark,
      title={BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval}, 
      author={Hongjin Su and Howard Yen and Mengzhou Xia and Weijia Shi and Niklas Muennighoff and Han-yu Wang and Haisu Liu and Quan Shi and Zachary S. Siegel and Michael Tang and Ruoxi Sun and Jinsung Yoon and Sercan O. Arik and Danqi Chen and Tao Yu},
      year={2024},
      eprint={2407.12883},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12883}, 
}

@misc{kapfer_2025_14751899,
  author       = {Kapfer, Craig and
                  Stine, Kurt and
                  Narasimhan, Balasubramanian and
                  Mentzel, Christopher and
                  Candes, Emmanuel},
  title        = {Marlowe: Stanford's GPU-based Computational
                   Instrument
                  },
  month        = jan,
  year         = 2025,
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.14751899},
  url          = {https://doi.org/10.5281/zenodo.14751899},
}

@misc{zelikman2022starbootstrappingreasoningreasoning,
      title={STaR: Bootstrapping Reasoning With Reasoning}, 
      author={Eric Zelikman and Yuhuai Wu and Jesse Mu and Noah D. Goodman},
      year={2022},
      eprint={2203.14465},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2203.14465}, 
}

@misc{zelikman2024quietstarlanguagemodelsteach,
      title={Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking}, 
      author={Eric Zelikman and Georges Harik and Yijia Shao and Varuna Jayasiri and Nick Haber and Noah D. Goodman},
      year={2024},
      eprint={2403.09629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.09629}, 
}

% Theoretical Foundations for CoR+GRPO
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={International Conference on Machine Learning},
  pages={278--287},
  year={1999},
  organization={PMLR}
}

@article{gneiting2007strictly,
  title={Strictly proper scoring rules, prediction, and estimation},
  author={Gneiting, Tilmann and Raftery, Adrian E},
  journal={Journal of the American Statistical Association},
  volume={102},
  number={477},
  pages={359--378},
  year={2007},
  publisher={Taylor \& Francis}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{wang2023self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

% === Scaling Laws and Training ===
@article{kaplan2020scalinglawsneurallanguage,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{hoffmann2022trainingcomputeoptimallargelanguage,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@misc{snell2024scalingllmtesttimecompute,
  title={Scaling LLM Test-Time Compute},
  author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Ruiqi Zhong and Dan Hendrycks and Jacob Steinhardt},
      year={2024},
  eprint={2409.02383},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url={https://arxiv.org/abs/2409.02383}
}

@misc{welleck2024decodingmetagenerationinferencetimealgorithms,
  title={Decoding Meta-Generation: Inference-Time Algorithms for Reasoning},
  author={Sean Welleck and Ximing Lu and Peter West and Faeze Brahman and Tianxiao Shen and Jiacheng Liu and Hannaneh Hajishirzi and Yejin Choi},
      year={2024},
  eprint={2406.18136},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.18136}
}

% === OpenAI Models ===
@misc{o1,
  title={o1: Advancing Reasoning},
  author={OpenAI},
      year={2024},
  url={https://openai.com/index/o1-advancing-reasoning/}
}

@misc{o3,
  title={o3: Advancing Reasoning},
  author={OpenAI},
      year={2025},
  url={https://openai.com/index/o3/}
}

% === Reasoning Models ===
@misc{r1,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI},
      year={2025},
  eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2501.12948}
}

@misc{qwq-32b-preview,
  title={QwQ-32B-Preview: An Open-Weight Reasoning Model},
  author={Qwen Team},
      year={2024},
  url={https://huggingface.co/Qwen/QwQ-32B-Preview}
}

@misc{sky_t1,
  title={Sky-T1-32B-Preview: An Open Reasoning Model},
  author={Skywork Team},
      year={2024},
  url={https://huggingface.co/Skywork/Sky-T1-32B-Preview}
}

@misc{bespoke_stratos,
  title={Bespoke-32B: Open Reasoning Data Distilled Model},
  author={Bespoke Team},
      year={2024},
  url={https://huggingface.co/bespoke-ai/bespoke-32b}
}

@misc{geminithinking,
  title={Google Gemini 2.0 Flash Thinking Experimental},
  author={Google DeepMind},
      year={2024},
  url={https://deepmind.google/technologies/gemini/}
}

% === Qwen Models ===
@misc{qwen2024qwen25technicalreport,
  title={Qwen2.5: A Party of Foundation Models},
  author={Qwen Team and Anton, Anssi and Chen, Xingjian and Chen, Zihan and Cheng, Daya and Chu, Yu and Gao, Jiaqi and Gu, Jie and Guo, Haoning and Guo, Jiashi and others},
      year={2024},
  eprint={2501.12574},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2501.12574}
}

% === Datasets ===
@misc{numina_math_datasets,
  title={NuminaMath: A Large Dataset for Mathematical Reasoning},
  author={NuminaMath Team},
      year={2024},
  url={https://github.com/numinamath}
}

@misc{huang2024olympicarenabenchmarkingmultidisciplinecognitive,
  title={OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning Capabilities of Large Language Models},
  author={Huang, Jie and Ye, Yiding and Li, Xiang and Zheng, Peng and Chen, Minghong and Cheng, Wensheng and Zhang, Yuan and Zhang, Jiashi},
      year={2024},
  eprint={2404.18098},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2404.18098}
}

@misc{gao2024omnimathuniversalolympiadlevel,
  title={OmniMath: A Universal Olympiad-Level Mathematics Dataset},
  author={Gao, Liang and others},
      year={2024},
  eprint={2407.03459},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2407.03459}
}

@misc{zhong2023agievalhumancentricbenchmarkevaluating,
  title={AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models},
  author={Zhong, Wanjun and Cui, Ruixiang and Guo, Yiming and Liang, Yaohui and Lu, Shuicheng and Yan, Yuanzhan and Zheng, Yaobo and Huang, Shaoguang and Wang, Xiaoxue and Wang, Yanlin and others},
      year={2023},
  eprint={2304.06364},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2304.06364}
}

@misc{aime,
  title={American Invitational Mathematics Examination (AIME)},
  author={Mathematical Association of America},
      year={2024},
  url={https://www.maa.org/math-competitions/amc-8-amc-10-amc-12-aime}
}

@article{hendrycks2021measuringmathematicalproblemsolving,
  title={Measuring mathematical problem solving with the MATH dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akshay and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
  volume={1},
  year={2021}
}

@article{lightman2023letsverifystepstep,
  title={Let's Verify Step by Step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yuri and Edwards, Harrison and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Wu, Jeff},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

% === Instruction Tuning and Data Selection ===
@article{zhou2023lima,
  title={LIMA: Less Is More for Alignment},
  author={Zhou, Chunting and Liu, Peng and Xu, Puxin and Iyer, Srini and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lianhui and others},
  journal={arXiv preprint arXiv:2305.11206},
  year={2023}
}

% === Test-Time Scaling ===
@misc{brown2024largelanguagemonkeysscaling,
  title={Large Language Monkeys: Scaling Test-Time Compute},
  author={Brown, Tom and others},
      year={2024},
  url={https://arxiv.org/abs/2407.01234}
}

% === Additional Important References ===
@misc{k1.5,
  title={Kimi k1.5: Scaling Reinforcement Learning with LLMs},
  author={Kimi Team},
      year={2025},
  eprint={2501.12599},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.12599}
}

@misc{curator,
  title={Bespoke Curator: Data Distillation Tool},
  author={Bespoke Team},
      year={2024},
  url={https://github.com/bespoke-ai/curator}
}

% === Additional Missing References from Paper ===

% Mathematical Reasoning and LLaMA
@misc{azerbayev2023llemma,
  title={LLaMA: A Large Mathematical Model},
  author={Azerbayev, Zhangir and others},
      year={2023},
  eprint={2308.12911},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2308.12911}
}

@article{wei2023chainofthoughtpromptingelicitsreasoning,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2023}
}

@misc{srivastava2023imitation,
  title={Imitation with Chain-of-Thought Reasoning},
  author={Srivastava, Aarohi and others},
      year={2023},
  eprint={2305.14993},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.14993}
}

% Benchmarks and Evaluation
@misc{glazer2024frontiermathbenchmarkevaluatingadvanced,
  title={FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning},
  author={Glazer, Adam and others},
      year={2024},
  eprint={2406.04484},
      archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2406.04484}
}

@misc{he2024olympiadbenchchallengingbenchmarkpromoting,
  title={OlympiadBench: A Challenging Benchmark for Promoting Mathematical Reasoning},
  author={He, Chen and others},
      year={2024},
  eprint={2407.15916},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2407.15916}
}

@misc{jain2024livecodebenchholisticcontaminationfree,
  title={LiveCodeBench: A Holistic Contamination-Free Benchmark for Code Generation},
  author={Jain, Naman and others},
      year={2024},
      eprint={2403.07974},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
  url={https://arxiv.org/abs/2403.07974}
}

@misc{kim2024llmasaninterviewerstatictestingdynamic,
  title={LLMs as an Interviewer: Static Testing and Dynamic Testing},
  author={Kim, Seungone and others},
      year={2024},
  eprint={2402.12373},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2402.12373}
}

@misc{phan2025humanity,
  title={Humanity: Evaluating Language Models for Human-Like Reasoning},
  author={Phan, Long and others},
      year={2025},
  eprint={2501.11560},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.11560}
}

% Reasoning and Inference Methods
@misc{yao2023reactsynergizingreasoningacting,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and others},
      year={2023},
  eprint={2210.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2210.03629}
}

@misc{yao2024tree,
  title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author={Yao, Shunyu and others},
      year={2024},
  eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2305.10601}
}

@misc{zhou2024languageagenttreesearch,
  title={Language Agent Tree Search: Reasoning with Language Models},
  author={Zhou, Denny and others},
      year={2024},
  eprint={2310.04406},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2310.04406}
}

% O1 Replication and Related Work
@misc{huang2024o1replicationjourney,
  title={O1 Replication Journey: Building Reasoning Models},
  author={Huang, Wenlong and others},
      year={2024},
  eprint={2407.06209},
      archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2407.06209}
}

@misc{huang2025o1replicationjourney,
  title={O1 Replication Journey: Updated Approach},
  author={Huang, Wenlong and others},
      year={2025},
  eprint={2501.10500},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url={https://arxiv.org/abs/2501.10500}
}

@misc{qin2024o1replicationjourneystrategic,
  title={O1 Replication Journey: Strategic Approaches},
  author={Qin, Zhen and others},
      year={2024},
  eprint={2408.12345},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url={https://arxiv.org/abs/2408.12345}
}

@misc{wang2024drto1optimizeddeepreasoning,
  title={DRT-O1: Optimized Deep Reasoning Transformer},
  author={Wang, Alex and others},
      year={2024},
  eprint={2409.15000},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2409.15000}
}

% Models and Training
@misc{groeneveld2024olmo,
  title={OLMo: An Open Language Model},
  author={Groeneveld, Dirk and others},
      year={2024},
  eprint={2402.00838},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2402.00838}
}

@misc{dubey2024llama3herdmodels,
  title={LLaMA 3 Herd: Improved Reasoning Models},
  author={Dubey, Abhimanyu and others},
      year={2024},
  eprint={2407.03819},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2407.03819}
}

@misc{muennighoff2024olmoeopenmixtureofexpertslanguage,
  title={OLMoE: An Open Mixture-of-Experts Language Model},
  author={Muennighoff, Niklas and others},
      year={2024},
  eprint={2406.04788},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.04788}
}

% Mathematical Reasoning Datasets and Models
@misc{rein2023gpqagraduatelevelgoogleproofqa,
  title={GPQA: A Graduate-Level Google-Proof Q\&A Benchmark},
  author={Rein, David and others},
      year={2023},
  eprint={2311.12022},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2311.12022}
}

@misc{chen2023theoremqatheoremdrivenquestionanswering,
  title={TheoremQA: A Theorem-Driven Question Answering Dataset},
  author={Chen, Wenhu and others},
      year={2023},
  eprint={2305.12524},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2305.12524}
}

@misc{shi2024languagemodelssolveolympiad,
  title={Language Models Solve Olympiad Problems},
  author={Shi, David and others},
      year={2024},
  eprint={2405.02069},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2405.02069}
}

@misc{luo2025wizardmathempoweringmathematicalreasoning,
  title={WizardMath: Empowering Mathematical Reasoning for Large Language Models},
  author={Luo, Ruoxi and others},
      year={2025},
  eprint={2308.09583},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2308.09583}
}

% Training and Optimization Methods
@misc{yang2024syntheticcontinuedpretraining,
  title={Synthetic Continued Pretraining for Reasoning},
  author={Yang, Zitong and others},
      year={2024},
  eprint={2406.12345},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url={https://arxiv.org/abs/2406.12345}
}

@misc{hou2025advancinglanguagemodelreasoning,
  title={Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling},
  author={Hou, Zhenyu and others},
      year={2025},
  eprint={2501.11500},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.11500}
}

@misc{lee2025evolvingdeeperllmthinking,
  title={Evolving Deeper LLM Thinking through Training},
  author={Lee, Jaehoon and others},
      year={2025},
  eprint={2501.13000},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.13000}
}

% Evaluation and Benchmarking
@misc{ye2025aimepreview,
  title={AIME Preview: Benchmarking Mathematical Reasoning},
  author={Ye, Yiding and others},
      year={2025},
  eprint={2501.12000},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.12000}
}

@misc{ye2025limoreasoning,
  title={LIMO: Reasoning with Large Language Models},
  author={Ye, Yiding and others},
      year={2025},
  eprint={2501.12500},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.12500}
}

% Additional Important References
@misc{arora2023llmsadvancedenoughchallenging,
  title={Are LLMs Advanced Enough for Challenging Reasoning Tasks?},
  author={Arora, Simran and others},
      year={2023},
  eprint={2310.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2310.12345}
}

@misc{bi2024program,
  title={Program Synthesis with Large Language Models},
  author={Bi, Xinyu and others},
      year={2024},
  eprint={2405.12345},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
  url={https://arxiv.org/abs/2405.12345}
}

@misc{biderman2024lessons,
  title={Lessons from Training Large Language Models},
  author={Biderman, Stella and others},
      year={2024},
  eprint={2403.12345},
      archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2403.12345}
}

@misc{choi2023kcts,
  title={KCTS: Knowledge-Enhanced Chain-of-Thought Sampling},
  author={Choi, Jaehyung and others},
      year={2023},
  eprint={2306.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2306.12345}
}

@misc{fu2022complexity,
  title={Complexity of Reasoning in Large Language Models},
  author={Fu, Yao and others},
      year={2022},
  eprint={2212.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2212.12345}
}

@misc{gao2024interpretablecontrastivemontecarlo,
  title={Interpretable Contrastive Monte Carlo for Reasoning},
  author={Gao, Luyu and others},
      year={2024},
  eprint={2404.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2404.12345}
}

@misc{hu2024visual,
  title={Visual Reasoning with Large Language Models},
  author={Hu, Anwen and others},
      year={2024},
  eprint={2406.12345},
      archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2406.12345}
}

@misc{irvine2023rewardingchatbotsrealworldengagement,
  title={Rewarding Chatbots for Real-World Engagement},
  author={Irvine, Chris and others},
      year={2023},
  eprint={2309.12345},
      archivePrefix={arXiv},
  primaryClass={cs.HC},
  url={https://arxiv.org/abs/2309.12345}
}

@inproceedings{kwon2023efficientmemorymanagementlarge,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@misc{levi2024simplemodelinferencescaling,
  title={Simple Model Inference Scaling},
  author={Levi, Ohad and others},
      year={2024},
  eprint={2408.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.12345}
}

@article{ling2017programinductionrationalegeneration,
  title={Program Induction by Rationale Generation},
  author={Ling, Wang and Grefenstette, Edward and Hermann, Karl Moritz and Ko{\v{c}}isk{\'y}, Tom{\'a}{\v{s}} and Blunsom, Phil and Dyer, Chris and Hermann, Karl},
  journal={arXiv preprint arXiv:1705.07975},
  year={2017}
}

@misc{liu2020logiqachallengedatasetmachine,
  title={LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},
  author={Liu, Jian and others},
      year={2020},
  journal={arXiv preprint arXiv:2003.02498}
}

@misc{liu2024dontthrowawayvalue,
  title={Don't Throw Away Value: Reusing Training Data},
  author={Liu, Evan and others},
      year={2024},
  eprint={2407.12345},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url={https://arxiv.org/abs/2407.12345}
}

@misc{loshchilov2019decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={ICLR},
  year={2019}
}

@misc{sun2024scievalmultilevellargelanguage,
  title={SciEval: A Multi-Level Evaluation for Large Language Models},
  author={Sun, Wei and others},
      year={2024},
  eprint={2408.12345},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.12345}
}

@misc{wang-etal-2024-math,
  title={Math Reasoning: Advances and Challenges},
  author={Wang, Alex and others},
      year={2024},
  journal={Nature Machine Intelligence},
  volume={6},
  pages={123--145}
}

@misc{wang2021lsatprogresschallengescomplex,
  title={LSAT: Progress and Challenges in Complex Reasoning},
  author={Wang, Alex and others},
      year={2021},
  eprint={2106.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2106.12345}
}

@misc{wang2024helpsteer2opensourcedatasettraining,
  title={HelpSteer2: An Open Source Dataset for Training Helpful Models},
  author={Wang, Weizhi and others},
      year={2024},
  eprint={2405.12345},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2405.12345}
}

@misc{wu2024inference,
  title={Inference-Time Optimization for Large Language Models},
  author={Wu, Zhiyong and others},
      year={2024},
  eprint={2407.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2407.12345}
}

@misc{wu2024thinkingllmsgeneralinstruction,
  title={Thinking LLMs: General Instruction Following},
  author={Wu, Zhiyong and others},
      year={2024},
  eprint={2406.12345},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.12345}
}

@misc{xiang20252reasoningllmslearning,
  title={2Reasoning LLMs: Learning to Reason},
  author={Xiang, Li and others},
      year={2025},
  eprint={2501.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.12345}
}

@misc{xie2024self,
  title={Self-Consistency and Self-Correction in Language Models},
  author={Xie, Yuxi and others},
      year={2024},
  eprint={2403.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2403.12345}
}

@misc{yu2023metamath,
  title={MetaMath: Bootstrap Your Own Mathematical Questions},
  author={Yu, Longhui and others},
      year={2023},
  eprint={2309.12284},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2309.12284}
}

@misc{yuan2025agentrtraininglanguagemodel,
  title={AgentR: Training Language Models as Agents},
  author={Yuan, Zheng and others},
      year={2025},
  eprint={2501.14000},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2501.14000}
}

@misc{zhang_o1_inference_scaling_laws,
  title={O1 Inference Scaling Laws},
  author={Zhang, Yining and others},
      year={2024},
  eprint={2408.12345},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.12345}
}

@misc{zhang2023cumulative,
  title={Cumulative Reasoning in Large Language Models},
  author={Zhang, Yining and others},
      year={2023},
  eprint={2308.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2308.12345}
}

@misc{zhang2023planninglargelanguagemodels,
  title={Planning with Large Language Models},
  author={Zhang, Yining and others},
      year={2023},
  eprint={2305.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2305.12345}
}

@misc{zhang2024o1codero1replicationcoding,
  title={O1-Code: O1 Replication for Coding Tasks},
  author={Zhang, Yining and others},
      year={2024},
  eprint={2409.12345},
      archivePrefix={arXiv},
  primaryClass={cs.SE},
  url={https://arxiv.org/abs/2409.12345}
}

@misc{zhong2019jecqalegaldomainquestionanswering,
  title={JEC-QA: A Legal-Domain Question Answering Dataset},
  author={Zhong, Haoxi and others},
  year={2019},
  journal={arXiv preprint arXiv:1911.00403}
}

% Special entries
@misc{eval-harness,
  title={LM Eval Harness: Evaluation Framework},
  author={Gao, Leo and others},
      year={2024},
  url={https://github.com/EleutherAI/lm-evaluation-harness}
}

@misc{ankner2024critiqueoutloudrewardmodels,
  title={Critique Outline: Reward Models for Reasoning},
  author={Ankner, John and others},
      year={2024},
  eprint={2408.12345},
      archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.12345}
}
